{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d342d3-d4a5-46ab-b2ad-5b286bfab5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_mpl_table(data, col_width=25.0, row_height=0.525, font_size=10,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in mpl_table._cells.items():\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax.get_figure(), ax\n",
    "\n",
    "fig,ax = render_mpl_table(dfred, header_columns=0, col_width=2.0)\n",
    "fig.savefig(\"table_mpl.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbd041-de2a-405e-9abc-2dbeae5f7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2000red = df2000[['model_unique_name','out', 'val_accuracy_score','val_balanced_accuracy_score', 'val_explained_variance_score']].copy()\n",
    "df250red = df250[['model_unique_name','out', 'val_accuracy_score','val_balanced_accuracy_score', 'val_explained_variance_score']].copy()\n",
    "\n",
    "df2000red = df2000red.rename(columns = {'val_accuracy_score':'val_accuracy_score_2000' ,'val_balanced_accuracy_score' : 'val_balanced_accuracy_score_2000', 'val_explained_variance_score':'val_explained_variance_score_2000'})\n",
    "df250red = df250red.rename(columns = {'val_accuracy_score':'val_accuracy_score_250' ,'val_balanced_accuracy_score' : 'val_balanced_accuracy_score_250', 'val_explained_variance_score':'val_explained_variance_score_250'})\n",
    "\n",
    "#we create a column with the important metric for each task 2000\n",
    "df2000red['val_metric_2000'] = df2000red['val_balanced_accuracy_score_2000'][(df2000red['out'] == 'sex')]\n",
    "df2000red['val_metric_2000'].update(df2000red['val_balanced_accuracy_score_2000'][(df2000red['out'] == 'mood_disorder')])\n",
    "df2000red['val_metric_2000'].update(df2000red['val_accuracy_score_2000'][(df2000red['out'] == 'srt_right_ear_classification')])\n",
    "df2000red['val_metric_2000'].update(df2000red['val_accuracy_score_2000'][(df2000red['out'] == 'alc_int_freq')])\n",
    "df2000red['val_metric_2000'].update(df2000red['val_explained_variance_score_2000'][(df2000red['out'] == 'mean_fa_fornix')])\n",
    "\n",
    "#we create a column with the important metric for each task 250\n",
    "df250red['val_metric_250'] = df250red['val_balanced_accuracy_score_250'][(df250red['out'] == 'sex')]\n",
    "df250red['val_metric_250'].update(df250red['val_balanced_accuracy_score_250'][(df250red['out'] == 'mood_disorder')])\n",
    "df250red['val_metric_250'].update(df250red['val_accuracy_score_250'][(df250red['out'] == 'srt_right_ear_classification')])\n",
    "df250red['val_metric_250'].update(df250red['val_accuracy_score_250'][(df250red['out'] == 'alc_int_freq')])\n",
    "df250red['val_metric_250'].update(df250red['val_explained_variance_score_250'][(df250red['out'] == 'mean_fa_fornix')])\n",
    "\n",
    "          \n",
    "df2000red = df2000red.sort_values('out')\n",
    "df250red = df250red.sort_values('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0133b9d-8381-4d67-aab0-68d392d599fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric_2000 = df2000red['val_metric_2000'].tolist()\n",
    "#val_metric_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df813352-e620-4a43-8aca-c0407174adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfred = df250red.copy()\n",
    "dfred[['val_accuracy_score_2000', 'val_balanced_accuracy_score_2000','val_explained_variance_score_2000','val_metric_2000']] = df2000red[['val_accuracy_score_2000', 'val_balanced_accuracy_score_2000','val_explained_variance_score_2000', 'val_metric_2000']]\n",
    "#dfred[['val_accuracy_score_8000', 'val_balanced_accuracy_score_8000','val_explained_variance_score_8000']] = df8000red[['val_accuracy_score_8000', 'val_balanced_accuracy_score_8000','val_explained_variance_score_8000']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8180d-b5f1-4851-a5d6-6ca3e7341e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.unique(dfred['out'].tolist())\n",
    "model_unique_name = pd.unique(dfred['model_unique_name'].tolist())\n",
    "val_accuracy_score_250 = dfred['val_accuracy_score_250'].tolist()\n",
    "val_accuracy_score_2000 = dfred['val_accuracy_score_2000'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1329d-747a-47bb-a88d-e9f30ccad20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_rate(data, label, metric):\n",
    "    df = data[(data['out'] == label)]\n",
    "    df = data[['model_unique_name', f\"{metric}_250\", f\"{metric}_2000\"]].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef399c-ef1a-4351-90a5-f3151ded90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfred[(dfred['out'] == 'sex')]\n",
    "model_unique_name = data['model_unique_name'].tolist()\n",
    "val_accuracy_score_250 = data['val_accuracy_score_250'].tolist()\n",
    "val_accuracy_score_2000 = data['val_accuracy_score_2000'].tolist()\n",
    "label = 'sex'\n",
    "metric = 'val_accuracy_score'\n",
    "sample_size = [250, 2000]\n",
    "twofifty = [250] * 105\n",
    "#df = data[['model_unique_name', f\"{metric}_250\", f\"{metric}_2000\"]].copy()\n",
    "#df.plot(kind='scatter',x=sample_size,y=f'val_accuracy_score_{sample_size}',color='blue', figsize =(22, 8), title=f'{label}')\n",
    "\n",
    "for index, model in enumerate(model_unique_name):\n",
    "    \n",
    "    val_scores = [val_accuracy_score_250[index], val_accuracy_score_2000[index]]  \n",
    "    nsamples = [sample_size] * len(val_accuracy_score_250)\n",
    "    plt.errorbar(nsamples[index],val_scores, label = model, )\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfb54f-4b5d-4de9-a46b-5e25679240fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasex = dfred[(dfred['out'] == 'sex')]\n",
    "sns.relplot(data=datasex, kind ='line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21662c5a-a99f-434b-9a35-df89d0e199ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftask = dfred[(dfred['out'] == 'mood_disorder')]\n",
    "for model in model_unique_name: \n",
    "    sns.lineplot(  \n",
    "           data= dfred[(dfred['model_unique_name'] == f'{model}')][(dfred['out'] == 'srt_right_ear_classification')], \n",
    "           x='nsamples', y='val_metric',  label = f'{model}', err_style=\"bars\", style='TL_type', legend = False)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667e6f0-4974-4d0e-9dd7-86c93498477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to compute the mean and standard deviation of the 3cv\n",
    "dfredstats = pd.DataFrame({'out':['NaN']* (len(out)*len(model_unique_name)), 'model_unique_name':['NaN']*35, 'mean_250':['NaN']*35,'std_250':['NaN']*35, 'mean_2000':['NaN']*35, 'std_2000':['NaN']*35})\n",
    "mean_250, std_250, mean_2000, std_2000, modellist, outlist = [], [],[],[],[],[]\n",
    "for task in out:\n",
    "    dfredstats['out'].update(dfredstats['out'][(dfredstats['out'] == 'mood_disorder')])\n",
    "    for index, model in enumerate(model_unique_name):\n",
    "        mean_250.append(pd.Series.mean(dfred['val_metric_250'][(dfred['model_unique_name'] == f'{model}')]))\n",
    "        std_250.append(pd.Series.std(dfred['val_metric_250'][(dfred['model_unique_name'] == f'{model}')]))\n",
    "        mean_2000.append(pd.Series.mean(dfred['val_metric_2000'][(dfred['model_unique_name'] == f'{model}')]))\n",
    "        std_2000.append(pd.Series.std(dfred['val_metric_2000'][(dfred['model_unique_name'] == f'{model}')]))\n",
    "        modellist.append(model)\n",
    "        outlist.append(task)\n",
    "dfredstats['model_unique_name'] = modellist\n",
    "dfredstats['out'] = outlist\n",
    "dfredstats['std_250'] = std_250\n",
    "dfredstats['mean_2000'] = mean_2000\n",
    "dfredstats['std_2000'] = std_2000\n",
    "dfredstats['mean_250'] = mean_250\n",
    "        #dfredstats['mean_8000'] = mean_8000\n",
    "        #dfredstats['std_8000'] = std_8000\n",
    "        #print(task, model, mean_250, std_250, mean_2000, std_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b09303-7b26-4bed-b9e5-0fd30d774dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_and_label(df, label, metric, n_samples):\n",
    "    data = df[(df['out'] == label)]\n",
    "    dflbl = data[['model_unique_name', f\"{metric}_250\", f\"{metric}_2000\"]].copy()\n",
    "    dflbl.plot(kind='scatter',x='model_unique_name',y=f'{metric}_{n_samples}',color='blue', figsize =(22, 8), title=f'{label}')\n",
    "    plt.show()\n",
    "    \n",
    "plot_metric_and_label(dfred, 'srt_right_ear_classification', 'val_accuracy_score', '250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608e35e-46d0-4ab0-b79c-50ea7b6cd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftask = dfred[(dfred['out'] == 'mood_disorder')]\n",
    "for model in model_unique_name: \n",
    "    sns.lineplot(kind='point',\n",
    "           data= dfred[(dfred['model_unique_name'] == f'{model}')][(dfred['out'] == 'sex')], \n",
    "           x='nsamples', y='val_balanced_accuracy_score', col = 'model_unique_name', label = f'{model}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
